{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baseline_header",
   "metadata": {},
   "source": [
    "# Baseline CAM Inference and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a866f16",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/ai-competition-baselines\n",
    "!python -m src.stage3_localization.weak_cam.infer \\\n",
    "  --config configs/stage3_weak_cam.yaml \\\n",
    "  --data_root \"$DATA_ROOT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d26764",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/ai-competition-baselines\n",
    "!python -m src.stage3_localization.weak_cam.eval_pointing_game \\\n",
    "  --config configs/stage3_weak_cam.yaml \\\n",
    "  --data_root \"$DATA_ROOT\" \\\n",
    "  --radius 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom_implementation_header",
   "metadata": {},
   "source": [
    "# Custom Stage 3 CAM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_annotations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Prepare Pointing Game Annotations CSV\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "\n",
    "ROBOFLOW_ROOT = os.path.join(\n",
    "    \"/content/drive/MyDrive/stage3_cam\",\n",
    "    dataset.location\n",
    ")\n",
    "\n",
    "OUTPUT_ROOT = \"/content/drive/MyDrive/stage3_cam/data_stage3\"\n",
    "\n",
    "IMG_DST = os.path.join(OUTPUT_ROOT, \"images\")\n",
    "ANN_DST = os.path.join(OUTPUT_ROOT, \"annotations\")\n",
    "\n",
    "os.makedirs(IMG_DST, exist_ok=True)\n",
    "os.makedirs(ANN_DST, exist_ok=True)\n",
    "\n",
    "data_yaml_path = os.path.join(ROBOFLOW_ROOT, \"data.yaml\")\n",
    "with open(data_yaml_path, \"r\") as f:\n",
    "    yolo_data = yaml.safe_load(f)\n",
    "\n",
    "class_names = yolo_data[\"names\"]\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "val_img_src = os.path.join(ROBOFLOW_ROOT, \"valid\", \"images\")\n",
    "val_label_src = os.path.join(ROBOFLOW_ROOT, \"valid\", \"labels\")\n",
    "\n",
    "rows = []\n",
    "\n",
    "img_files = [\n",
    "    f for f in os.listdir(val_img_src)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "\n",
    "for img_file in img_files:\n",
    "    src_img_path = os.path.join(val_img_src, img_file)\n",
    "    dst_img_path = os.path.join(IMG_DST, img_file)\n",
    "\n",
    "    shutil.copy2(src_img_path, dst_img_path)\n",
    "\n",
    "    label_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "    label_path = os.path.join(val_label_src, label_file)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(src_img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    img_h, img_w = img.shape[:2]\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "\n",
    "            class_id = int(parts[0])\n",
    "            x_center_norm = float(parts[1])\n",
    "            y_center_norm = float(parts[2])\n",
    "\n",
    "            x = x_center_norm * img_w\n",
    "            y = y_center_norm * img_h\n",
    "\n",
    "            rows.append({\n",
    "                \"image_id\": img_file,\n",
    "                \"class_id\": class_id,\n",
    "                \"class_name\": class_names[class_id],\n",
    "                \"x\": x,\n",
    "                \"y\": y\n",
    "            })\n",
    "\n",
    "points_df = pd.DataFrame(rows)\n",
    "csv_path = os.path.join(ANN_DST, \"pointing_game.csv\")\n",
    "points_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"\\nPointing game CSV created\")\n",
    "print(f\"Images processed : {len(img_files)}\")\n",
    "print(f\"Total points     : {len(points_df)}\")\n",
    "print(f\"Saved to         : {csv_path}\")\n",
    "\n",
    "points_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_definitions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11: Model Definitions\n",
    "\n",
    "%%writefile /content/drive/MyDrive/stage3_cam/project_stage3/src/stage1_binary/model.py\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "def build_model(backbone: str, num_classes: int = 2, pretrained: bool = True, dropout: float = 0.2) -> nn.Module:\n",
    "    return timm.create_model(backbone, pretrained=pretrained, num_classes=num_classes, drop_rate=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stage2_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /content/drive/MyDrive/stage3_cam/project_stage3/src/stage2_multilabel/model.py\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "def build_model(backbone: str, num_labels: int = 3, pretrained: bool = True, dropout: float = 0.2) -> nn.Module:\n",
    "    return timm.create_model(backbone, pretrained=pretrained, num_classes=num_labels, drop_rate=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cam_utilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12: CAM Utilities (Revised)\n",
    "%%writefile /content/drive/MyDrive/stage3_cam/project_stage3/src/stage3_localization/weak_cam/cam.py\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "@dataclass\n",
    "class CamTargetConfig:\n",
    "    task: str\n",
    "    label_index: int = 0\n",
    "    class_index: int = 1\n",
    "\n",
    "class MultiLabelOutputTarget:\n",
    "    def __init__(self, label_index: int):\n",
    "        self.label_index = int(label_index)\n",
    "\n",
    "    def __call__(self, model_output: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Handles single-image (1D) or batch (2D) outputs for multi-label tasks.\n",
    "        \"\"\"\n",
    "        if model_output.dim() == 1:  # single image\n",
    "            return model_output[self.label_index]\n",
    "        elif model_output.dim() == 2:  # batch\n",
    "            return model_output[:, self.label_index]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected model output shape: {model_output.shape}\")\n",
    "\n",
    "def find_last_conv_layer(model: nn.Module) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Finds the last Conv2d layer in a model.\n",
    "    \"\"\"\n",
    "    last_conv = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            last_conv = m\n",
    "    if last_conv is None:\n",
    "        raise RuntimeError(\"No Conv2d layer found\")\n",
    "    return last_conv\n",
    "\n",
    "def build_cam_target(cfg: CamTargetConfig):\n",
    "    \"\"\"\n",
    "    Builds the appropriate GradCAM target object depending on the task.\n",
    "    \"\"\"\n",
    "    if cfg.task == \"stage1_binary\":\n",
    "        from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "        return ClassifierOutputTarget(int(cfg.class_index))\n",
    "    if cfg.task == \"stage2_multilabel\":\n",
    "        return MultiLabelOutputTarget(int(cfg.label_index))\n",
    "    raise ValueError(f\"Unknown task: {cfg.task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cam_inference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Full Stage 3 CAM Inference (Stage 1 + Stage 2)\n",
    "%%writefile /content/drive/MyDrive/stage3_cam/project_stage3/src/stage3_localization/weak_cam/infer.py\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.common.io import ensure_dir, list_images_from_dir\n",
    "from src.common.utils import get_device\n",
    "from src.common.transforms import get_eval_transforms\n",
    "\n",
    "from src.stage1_binary.model import build_model as build_stage1_model\n",
    "from src.stage2_multilabel.model import build_model as build_stage2_model\n",
    "from src.stage3_localization.weak_cam.cam import CamTargetConfig, build_cam_target, find_last_conv_layer\n",
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "# ---------------------------\n",
    "# Helper Functions\n",
    "# ---------------------------\n",
    "def load_yaml(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def load_model(task: str, stage_cfg_path: str, ckpt_path: str, device):\n",
    "    cfg = load_yaml(stage_cfg_path)\n",
    "    if task == \"stage1_binary\":\n",
    "        model = build_stage1_model(\n",
    "            backbone=cfg[\"model\"][\"backbone\"],\n",
    "            num_classes=int(cfg[\"model\"][\"num_classes\"]),\n",
    "            pretrained=False,\n",
    "            dropout=float(cfg[\"model\"][\"dropout\"])\n",
    "        )\n",
    "    elif task == \"stage2_multilabel\":\n",
    "        model = build_stage2_model(\n",
    "            backbone=cfg[\"model\"][\"backbone\"],\n",
    "            num_labels=int(cfg[\"model\"][\"num_labels\"]),\n",
    "            pretrained=False,\n",
    "            dropout=float(cfg[\"model\"][\"dropout\"])\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown task: {task}\")\n",
    "\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def overlay_cam(img_rgb, cam_mask, alpha=0.45):\n",
    "    heatmap = (cam_mask * 255.0).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap_rgb = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    return (alpha * heatmap_rgb + (1 - alpha) * img_rgb).astype(np.uint8)\n",
    "\n",
    "# ---------------------------\n",
    "# Main Inference\n",
    "# ---------------------------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", required=True, help=\"Path to stage3_weak_cam.yaml\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    cfg = load_yaml(args.config)\n",
    "    device = get_device()\n",
    "\n",
    "    # Direct paths from YAML\n",
    "    img_dir = cfg[\"data\"][\"img_dir\"]\n",
    "    out_dir = cfg[\"output\"][\"out_dir\"]\n",
    "\n",
    "    heat_dir_stage1 = os.path.join(out_dir, \"heatmaps_stage1\")\n",
    "    heat_dir_stage2 = os.path.join(out_dir, \"heatmaps_stage2\")\n",
    "    ov_dir_stage1 = os.path.join(out_dir, \"overlays_stage1\")\n",
    "    ov_dir_stage2 = os.path.join(out_dir, \"overlays_stage2\")\n",
    "\n",
    "    for d in [heat_dir_stage1, heat_dir_stage2, ov_dir_stage1, ov_dir_stage2]:\n",
    "        ensure_dir(d)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Load Stage 1 & Stage 2 models\n",
    "    # ---------------------------\n",
    "    stage1_cfg = cfg[\"model\"][\"stage1\"]\n",
    "    stage2_cfg = cfg[\"model\"][\"stage2\"]\n",
    "\n",
    "    model_stage1 = load_model(stage1_cfg[\"task\"], stage1_cfg[\"config_path\"], stage1_cfg[\"ckpt_path\"], device)\n",
    "    model_stage2 = load_model(stage2_cfg[\"task\"], stage2_cfg[\"config_path\"], stage2_cfg[\"ckpt_path\"], device)\n",
    "\n",
    "    cam_stage1 = GradCAM(model=model_stage1, target_layers=[find_last_conv_layer(model_stage1)])\n",
    "    cam_stage2 = GradCAM(model=model_stage2, target_layers=[find_last_conv_layer(model_stage2)])\n",
    "\n",
    "    # Transforms\n",
    "    tf = get_eval_transforms(int(cfg[\"cam\"][\"input_size\"]))\n",
    "\n",
    "    # Targets\n",
    "    target_stage1 = build_cam_target(CamTargetConfig(\n",
    "        task=stage1_cfg[\"task\"],\n",
    "        class_index=int(cfg[\"target\"][\"class_index\"])\n",
    "    ))\n",
    "\n",
    "    target_stage2 = build_cam_target(CamTargetConfig(\n",
    "        task=stage2_cfg[\"task\"],\n",
    "        class_index=int(cfg[\"target\"][\"class_index\"])\n",
    "    ))\n",
    "\n",
    "    # Images\n",
    "    images = list_images_from_dir(img_dir, \".jpg\")\n",
    "    images = images[:cfg[\"output\"].get(\"max_images\", 9999)]\n",
    "\n",
    "    for img_id in tqdm(images, desc=\"Stage3 CAM\"):\n",
    "        img_path = os.path.join(img_dir, img_id)\n",
    "        img_bgr = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        x = tf(image=img_rgb)[\"image\"].unsqueeze(0).to(device)\n",
    "\n",
    "        # ---------------------------\n",
    "        # Stage 1 CAM\n",
    "        # ---------------------------\n",
    "        cam_mask1 = cam_stage1(input_tensor=x, targets=[target_stage1])[0]\n",
    "\n",
    "        if cfg[\"output\"][\"save_heatmaps\"]:\n",
    "            heat1 = (cam_mask1 * 255.0).astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(heat_dir_stage1, img_id.replace(\".jpg\",\"_heat.png\")), heat1)\n",
    "\n",
    "        if cfg[\"output\"][\"save_overlays\"]:\n",
    "            cam_resized1 = cv2.resize(cam_mask1, (img_rgb.shape[1], img_rgb.shape[0]))\n",
    "            ov1 = overlay_cam(img_rgb, cam_resized1, float(cfg[\"output\"].get(\"overlay_alpha\",0.45)))\n",
    "            cv2.imwrite(os.path.join(ov_dir_stage1, img_id.replace(\".jpg\",\"_ov.jpg\")),\n",
    "                        cv2.cvtColor(ov1, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # ---------------------------\n",
    "        # Stage 2 CAM\n",
    "        # ---------------------------\n",
    "        cam_mask2 = cam_stage2(input_tensor=x, targets=[target_stage2])[0]\n",
    "\n",
    "        if cfg[\"output\"][\"save_heatmaps\"]:\n",
    "            heat2 = (cam_mask2 * 255.0).astype(np.uint8)\n",
    "            cv2.imwrite(os.path.join(heat_dir_stage2, img_id.replace(\".jpg\",\"_heat.png\")), heat2)\n",
    "\n",
    "        if cfg[\"output\"][\"save_overlays\"]:\n",
    "            cam_resized2 = cv2.resize(cam_mask2, (img_rgb.shape[1], img_rgb.shape[0]))\n",
    "            ov2 = overlay_cam(img_rgb, cam_resized2, float(cfg[\"output\"].get(\"overlay_alpha\",0.45)))\n",
    "            cv2.imwrite(os.path.join(ov_dir_stage2, img_id.replace(\".jpg\",\"_ov.jpg\")),\n",
    "                        cv2.cvtColor(ov2, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    print(f\"âœ… Stage 3 CAM outputs saved to {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_cam_inference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 18: Run CAM Inference\n",
    "\n",
    "%cd /content/drive/MyDrive/stage3_cam/project_stage3\n",
    "\n",
    "!PYTHONPATH=$PWD python -m src.stage3_localization.weak_cam.infer \\\n",
    "    --config configs/stage3_weak_cam.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stage1_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 16: Copy Stage 1 Config to Drive\n",
    "\n",
    "%%writefile /content/drive/MyDrive/stage1_results/stage1_binary.yaml\n",
    "data:\n",
    "  train_csv: train.csv\n",
    "  val_csv: val.csv\n",
    "  img_dir_train: /content/data_stage1/images/train\n",
    "  img_dir_val: /content/data_stage1/images/val\n",
    "  image_id_col: image_id\n",
    "  label_col: label\n",
    "\n",
    "model:\n",
    "  backbone: resnet50\n",
    "  num_classes: 2\n",
    "  img_size: 224\n",
    "  pretrained: true\n",
    "  dropout: 0.2\n",
    "\n",
    "train:\n",
    "  epochs: 10\n",
    "  batch_size: 32\n",
    "  lr: 0.0001\n",
    "  weight_decay: 0.0001\n",
    "  num_workers: 2\n",
    "  seed: 42\n",
    "  mixed_precision: true\n",
    "\n",
    "augment:\n",
    "  enabled: true\n",
    "  preset: stage1_safe\n",
    "\n",
    "eval:\n",
    "  primary_metric: macro_f1\n",
    "\n",
    "output:\n",
    "  best_ckpt_name: best_stage1.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_config_stage1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /content/drive/MyDrive/stage3_cam/project_stage3/configs/stage3_weak_cam_eval_stage1.yaml\n",
    "cam:\n",
    "  input_size: 224\n",
    "  target_layer: null\n",
    "\n",
    "data:\n",
    "  img_dir: /content/drive/MyDrive/stage3_cam/data_stage3/images\n",
    "  points_csv: /content/drive/MyDrive/stage3_cam/data_stage3/annotations/pointing_game.csv\n",
    "  image_id_col: image_id\n",
    "  x_col: x\n",
    "  y_col: y\n",
    "\n",
    "model:\n",
    "  task: stage1_binary\n",
    "  config_path: /content/drive/MyDrive/stage1_results/stage1_binary.yaml\n",
    "  ckpt_path: /content/drive/MyDrive/project/runs/stage1_binary/best_stage1.pt\n",
    "\n",
    "target:\n",
    "  class_index: 1\n",
    "  label_index: 0\n",
    "\n",
    "output:\n",
    "  out_dir: /content/drive/MyDrive/stage3_cam/project_stage3/outputs/cam_results\n",
    "  save_heatmaps: true\n",
    "  save_overlays: true\n",
    "  overlay_alpha: 0.45\n",
    "  max_images: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_config_stage2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /content/drive/MyDrive/stage3_cam/project_stage3/configs/stage3_weak_cam_eval_stage2.yaml\n",
    "cam:\n",
    "  input_size: 224\n",
    "  target_layer: null\n",
    "\n",
    "data:\n",
    "  img_dir: /content/drive/MyDrive/stage3_cam/data_stage3/images\n",
    "  points_csv: /content/drive/MyDrive/stage3_cam/data_stage3/annotations/pointing_game.csv\n",
    "  image_id_col: image_id\n",
    "  x_col: x\n",
    "  y_col: y\n",
    "\n",
    "model:\n",
    "  task: stage2_multilabel\n",
    "  config_path: /content/drive/MyDrive/project_stage2/configs/stage2_multilabel.yaml\n",
    "  ckpt_path: /content/drive/MyDrive/project_stage2/runs/stage2_multilabel/best_stage2.pt\n",
    "\n",
    "target:\n",
    "  class_index: 1\n",
    "  label_index: 0\n",
    "\n",
    "output:\n",
    "  out_dir: /content/drive/MyDrive/stage3_cam/project_stage3/outputs/cam_results\n",
    "  save_heatmaps: true\n",
    "  save_overlays: true\n",
    "  overlay_alpha: 0.45\n",
    "  max_images: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_pointing_game",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1\n",
    "!PYTHONPATH=$PWD python -m src.stage3_localization.weak_cam.eval_pointing_game \\\n",
    "    --config configs/stage3_weak_cam_eval_stage1.yaml \\\n",
    "    --data_root /content/drive/MyDrive/stage3_cam/data_stage3 \\\n",
    "    --radius 15\n",
    "\n",
    "# Stage 2\n",
    "!PYTHONPATH=$PWD python -m src.stage3_localization.weak_cam.eval_pointing_game \\\n",
    "    --config configs/stage3_weak_cam_eval_stage2.yaml \\\n",
    "    --data_root /content/drive/MyDrive/stage3_cam/data_stage3 \\\n",
    "    --radius 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 20: Visualize Stage-specific CAM Results with Pointing Game Points\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "stage = \"stage1\"\n",
    "\n",
    "output_dir = \"/content/drive/MyDrive/stage3_cam/project_stage3/outputs/cam_results\"\n",
    "overlay_dir = os.path.join(output_dir, f\"overlays_{stage}\")\n",
    "points_csv = \"/content/drive/MyDrive/stage3_cam/data_stage3/annotations/pointing_game.csv\"\n",
    "\n",
    "\n",
    "points_df = pd.read_csv(points_csv)\n",
    "\n",
    "if not os.path.exists(overlay_dir):\n",
    "    raise FileNotFoundError(f\"No overlays folder found for {stage}: {overlay_dir}\")\n",
    "\n",
    "overlay_files = [f for f in os.listdir(overlay_dir) if f.endswith('.jpg')]\n",
    "if not overlay_files:\n",
    "    print(\"No overlay images found in:\", overlay_dir)\n",
    "else:\n",
    "    overlay_files = overlay_files[:6]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, img_file in enumerate(overlay_files):\n",
    "        img_path = os.path.join(overlay_dir, img_file)\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "\n",
    "        points = points_df[points_df['image_id'] == img_file]\n",
    "        for _, row in points.iterrows():\n",
    "            axes[idx].scatter(row['x'], row['y'], c='lime', s=50, marker='x', linewidths=2)\n",
    "\n",
    "        axes[idx].set_title(f\"{stage.upper()} CAM + Points: {img_file}\", fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(output_dir, f\"cam_visualization_{stage}.png\")\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"{stage.upper()} CAM visualization saved to: {save_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {"name":"python"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
